{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:130%; text-align:left\">\n",
    "\n",
    "<h1 align=\"left\"><font color=blue>Description: </font></h1>\n",
    "    \n",
    "<p style=\"color:black;\">In this project, we aim to develop a sophisticated automated garbage classification system leveraging the ResNet50 pre-trained model architecture, utilizing the power of transfer learning in the Artificial Intelligence field. This notebook serves as the main entry point for the software of our automated garbage classification system. It connects the pre-trained model, the camera output, capacitive and inductive sensor outputs, motors and actuators to achieve the objectives of our project.</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:130%; text-align:left\">\n",
    "\n",
    "<h1 align=\"left\"><font color=blue>Dataset: </font></h1>\n",
    "    \n",
    "<p style=\"color:black;\">This project utilizes the \"TrashBox dataset\" for the ResNet50 model.\n",
    "Thhis dataset contains 17785 waste object images divided into seven classes (glass, plastic, metal, e-waste, cardboard, paper, medical waste) for training. \n",
    "\n",
    "<p style=\"color:black;\">The dataset contains 7 classes even though our project classifies trash into just 4 classes. The other classes, however, will not be removed but just ignored. This will allow for further future improvements if needed.  </p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px; padding: 15px; background-color:lavender; font-size:130%; text-align:left\">\n",
    "\n",
    "<h1 align=\"left\"><font color=blue>Objectives: </font></h1>\n",
    "    \n",
    "<ul style=\"color:black;\">\n",
    "    <li><strong>Employ Transfer Learning:</strong> Leverage a pre-trained ResNet50, adapting it for our specific dataset.</li>\n",
    "    <li><strong>Accept sensor data:</strong> Accept and clean all sensor data including optical, capacitive and inductive.</li>\n",
    "    <li><strong>Develop algorithm for predicting trash class:</strong> develop a multimodal approach leveraging all sensor data to make a prediction on the trash class.</li>\n",
    "    <li><strong>Motors & Actuators integration:</strong> Send the prediction to actuators to place trash in the correct pin.</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Initialization\"></a>\n",
    "# <p style=\"background-color: royalblue; font-family:calibri; color:white; font-size:140%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Step 1 | Initialization</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1. import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate and remove corrupted images\n",
    "def validate_and_remove_corrupted_images(directory):\n",
    "    for root, dirs, files in os.walk(directory): # search through all directories and files\n",
    "        for file in files: # search each file \n",
    "            if file.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')): # specifically search for pictures \n",
    "                file_path = os.path.join(root, file) \n",
    "                try:\n",
    "                    img = Image.open(file_path) # open the image file\n",
    "                    img.verify()  # Verify that it is an image\n",
    "                except (IOError, SyntaxError) as e: # if an exception pccurs\n",
    "                    print(f\"Removing bad file: {file_path} - {e}\") \n",
    "                    os.remove(file_path) # remove corrupted image from the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate and remove corrupted images from your training and validation sets\n",
    "validate_and_remove_corrupted_images('/Users/macbook/Desktop/TrashBox-main/TrashBox_train_set') \n",
    "validate_and_remove_corrupted_images('/Users/macbook/Desktop/TrashBox-testandvalid-main/TrashBox_testandvalid_set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained EfficientNet model\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n",
    "x = base_model.output \n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TrashBox dataset and fine-tune the model\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/macbook/Desktop/TrashBox-main/TrashBox_train_set', # train set path, change if run on different computer. \n",
    "    target_size=(224, 224), # image size \n",
    "    batch_size=32, # batch size \n",
    "    class_mode='categorical',  # categorical since we have 6 classes \n",
    "    shuffle=True  # Shuffle training data for better training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '/Users/macbook/Desktop/TrashBox-testandvalid-main/TrashBox_testandvalid_set/val',  # Point to 'val' subdirectory, change if run on different computer accordingly\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=False  # Don't shuffle validation data to keep it consistent \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy']) # compile model with adam optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after training\n",
    "model.save('trash_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model using the 'test' dataset\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    '/Users/macbook/Desktop/TrashBox-testandvalid-main/TrashBox_testandvalid_set/test',  # Point to 'test' subdirectory, change if run on different computer accordingly. \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}, Test Loss: {test_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = load_model('/Users/macbook/Desktop/trash_classification_model.h5')\n",
    "\n",
    "# Class labels \n",
    "class_labels = {\n",
    "    0: 'cardboard',\n",
    "    1: 'e-waste',\n",
    "    2: 'glass',\n",
    "    3: 'medical',\n",
    "    4: 'metal',\n",
    "    5: 'paper',\n",
    "    6: 'plastic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize webcam for real-time classification\n",
    "cap = cv2.VideoCapture(0) \n",
    "last_prediction_time = time.time()\n",
    "last_label = \"\"  # To store the last prediction label, initially empty\n",
    "last_probabilities = None  # To store the last prediction probabilities, initially None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True: # infinite loop, to run until stopped. \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # to get a prediction every 10 seconds, change and tune if needed. because 1 second is too little time to observe the results\n",
    "    # Check if 10 seconds have passed since the last prediction\n",
    "    current_time = time.time()\n",
    "    if current_time - last_prediction_time >= 10:\n",
    "        # Preprocess the frame for EfficientNet\n",
    "        img = cv2.resize(frame, (224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "\n",
    "        # Predict the class\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "        last_label = class_labels[predicted_class]  # Update the last prediction label\n",
    "        last_probabilities = predictions[0]  # Update the last prediction probabilities\n",
    "        last_prediction_time = current_time  # Update the last prediction time\n",
    "\n",
    "    # Display the last predicted label on the frame\n",
    "    if last_label:\n",
    "        cv2.putText(frame, f'Prediction: {last_label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the probabilistic output of the last prediction on the frame\n",
    "    if last_probabilities is not None:\n",
    "        for i, (label, prob) in enumerate(zip(class_labels.values(), last_probabilities)):\n",
    "            text = f'{label}: {prob:.2f}'\n",
    "            cv2.putText(frame, text, (10, 60 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame with the label and probabilities\n",
    "    cv2.imshow('Trash Classification', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() # for security and efficiency\n",
    "cv2.destroyAllWindows() # for security and efficiency\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
